{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "class SVC:\n",
    "    def __init__(self,C=1.0):\n",
    "        self.C=C\n",
    "        self.W_=0\n",
    "        self.b_=0\n",
    "        \n",
    "    def hingeLoss(self,X,Y,W,b):\n",
    "        loss=0.5*numpy.dot(W,W.T)\n",
    "        \n",
    "        m=X.shape[0]\n",
    "        \n",
    "        for i in range(m):\n",
    "            ti=Y[i]*(numpy.dot(W,X[i].T)+b)\n",
    "            loss+=self.C*max(0,1-ti)\n",
    "            \n",
    "        return loss[0][0]\n",
    "    \n",
    "    def fit(self,X,Y,batch_size=120,learning_rate=0.001,max_itr=400):\n",
    "        n=X.shape[1] # no. of features\n",
    "        m=X.shape[0] # no. of samplesimage_data,labels\n",
    "        \n",
    "        W=numpy.zeros((1,n))\n",
    "        b=0\n",
    "        \n",
    "        #training\n",
    "        losses=[]\n",
    "        \n",
    "        for _ in range(max_itr):\n",
    "            \n",
    "            l=self.hingeLoss(X,Y,W,b)\n",
    "            losses.append(l)\n",
    "            \n",
    "            #ids for mini batch\n",
    "            ids=numpy.arange(m)\n",
    "            numpy.random.shuffle(ids)\n",
    "             \n",
    "            #mini-batch gradient descent\n",
    "            for batch_start in range(0,m,batch_size):\n",
    "                gradw=0\n",
    "                gradb=0\n",
    "                for j in range(batch_start,batch_start+batch_size):\n",
    "                    if j<m:\n",
    "                        i=ids[j]\n",
    "                        ti=Y[i]*(numpy.dot(W,X[i].T)+b)\n",
    "\n",
    "                        if ti>1:\n",
    "                            gradw+=0\n",
    "                            gradb+=0\n",
    "                        else:\n",
    "                            gradw+=self.C*X[i]*Y[i]\n",
    "                            gradb+=self.C*Y[i]\n",
    "                \n",
    "                W= W - learning_rate*(W - gradw)\n",
    "                b= b + learning_rate*gradb\n",
    "            \n",
    "        self.W_=W\n",
    "        self.b_=b\n",
    "            \n",
    "        return self.W_,self.b_,losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import MySVM\n",
    "import numpy as np\n",
    "\n",
    "class OneVsOneSVM:\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    C : float, optional (default=1.0)\n",
    "    Penalty parameter C of the error term.\n",
    "    \n",
    "    max_iter : int, optional (default=6000)\n",
    "    \n",
    "    learning_rate : float, optional (default=0.00001)\n",
    "    \n",
    "    Callable Functions\n",
    "    ------------------\n",
    "    \n",
    "    fit(X,Y) : take data as X, target_labels as Y as input and trains the SVM model\n",
    "    \n",
    "    score(X,Y) : take data as X, target_labels as Y as input and returns the accuracy of the model\n",
    "    \n",
    "    '''\n",
    "    def __init__(self,C=1.0,max_iter=6000,learning_rate=0.00001):\n",
    "        self.max_iter=max_iter\n",
    "        self.learning_rate=learning_rate\n",
    "        self.C=C\n",
    "        self.svm_classifiers={}\n",
    "        \n",
    "    def generateClasswiseData(self,X,Y):\n",
    "        data={}\n",
    "\n",
    "        no_of_classes=len(np.unique(Y))\n",
    "        no_of_samples=X.shape[0]\n",
    "\n",
    "        for i in range(no_of_classes):\n",
    "            data[i]=[]\n",
    "\n",
    "        for i in range(no_of_samples):\n",
    "            data[Y[i]].append(X[i])\n",
    "\n",
    "        for k in range(no_of_classes):\n",
    "            data[k]=np.array(data[k])\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def getPairData(self,d1,d2):\n",
    "\n",
    "        l1=d1.shape[0]\n",
    "        l2=d2.shape[0]\n",
    "        data=np.zeros((l1+l2,d1.shape[1]))\n",
    "        labels=np.zeros(l1+l2)\n",
    "\n",
    "        data[:l1]=d1\n",
    "        data[l1:]=d2\n",
    "\n",
    "        labels[:l1]=1\n",
    "        labels[l1:]=-1\n",
    "\n",
    "        return data,labels\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        global le\n",
    "        le=LabelEncoder()\n",
    "        le.fit(Y)\n",
    "        Y=le.transform(Y)\n",
    "        \n",
    "        data=self.generateClasswiseData(X,Y)\n",
    "        svc=MySVM.SVC(self.C)\n",
    "        for i in range(len(data)):\n",
    "            self.svm_classifiers[i]={}\n",
    "            for j in range(i+1,len(np.unique(Y))):\n",
    "                x,y=self.getPairData(data[i],data[j])\n",
    "                wts,b,losses=svc.fit(x,y, learning_rate=self.learning_rate, max_itr=self.max_iter)\n",
    "                self.svm_classifiers[i][j]=(wts,b)      \n",
    "\n",
    "    def predict(self,X):\n",
    "        X=np.array(X)\n",
    "        classes=len(self.svm_classifiers)\n",
    "        count=np.zeros(classes,)\n",
    "        for i in range(classes):\n",
    "            for j in range(i+1,classes):\n",
    "                W = self.svm_classifiers[i][j][0]\n",
    "                b = self.svm_classifiers[i][j][1]\n",
    "                if (np.dot(W,X.T)+ b)>=0:\n",
    "                    count[i]+=1\n",
    "                else:\n",
    "                    count[j]+=1\n",
    "\n",
    "        index=np.argmax(count)\n",
    "        return le.inverse_transform([index])\n",
    "\n",
    "    def score(self,X,Y):\n",
    "        count=0\n",
    "        for i in range(X.shape[0]):\n",
    "            if Y[i]==self.predict(X[i]):\n",
    "                count+=1\n",
    "\n",
    "        return count/X.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.51%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# 1. Load dataset\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "newsgroups = fetch_20newsgroups(subset='all', categories=categories)\n",
    "\n",
    "# 2. Preprocess text and vectorize using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X = vectorizer.fit_transform(newsgroups.data).toarray()\n",
    "\n",
    "# 3. Encode labels\n",
    "y = newsgroups.target\n",
    "\n",
    "# 4. Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Initialize and fit the OneVsOneSVM model\n",
    "ovo_SVM = OneVsOneSVM(C=1.0, max_iter=6000, learning_rate=0.00001)\n",
    "ovo_SVM.fit(X_train, y_train)\n",
    "\n",
    "# 6. Evaluate the model\n",
    "accuracy = ovo_SVM.score(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: sci.med\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already trained the OneVsOneSVM model as shown in the previous example.\n",
    "\n",
    "# Custom text input\n",
    "custom_text = \"The latest advances in AI have revolutionized the tech industry.\"\n",
    "\n",
    "# 1. Preprocess and Vectorize the Custom Text\n",
    "custom_text_vectorized = vectorizer.transform([custom_text]).toarray()\n",
    "\n",
    "# 2. Predict the category\n",
    "predicted_category = ovo_SVM.predict(custom_text_vectorized)\n",
    "\n",
    "# 3. Convert the predicted numerical label back to the original category name\n",
    "predicted_category_name = newsgroups.target_names[predicted_category[0]]\n",
    "\n",
    "print(f\"Predicted Category: {predicted_category_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "primeai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
